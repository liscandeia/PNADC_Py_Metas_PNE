{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciou o download: Trimestre 2/2012 - aguarde.\n",
      "Download finalizado.\n",
      "Iniciou a criação do DataFrame Pandas: esta etapa pode demorar alguns minutos.\n",
      "Chunks processados e salvos.\n",
      "DataFrame criado.\n",
      "DataFrame \"pnad_trimestral_trimestre_022012.parquet\" salvo como arquivo Parquet em: db\\pnad_trimestral_trimestre_022012.parquet\n",
      "Iniciou o download: Trimestre 2/2013 - aguarde.\n",
      "Download finalizado.\n",
      "Iniciou a criação do DataFrame Pandas: esta etapa pode demorar alguns minutos.\n",
      "Chunks processados e salvos.\n",
      "DataFrame criado.\n",
      "DataFrame \"pnad_trimestral_trimestre_022013.parquet\" salvo como arquivo Parquet em: db\\pnad_trimestral_trimestre_022013.parquet\n",
      "Iniciou o download: Trimestre 2/2014 - aguarde.\n",
      "Download finalizado.\n",
      "Iniciou a criação do DataFrame Pandas: esta etapa pode demorar alguns minutos.\n",
      "Chunks processados e salvos.\n",
      "DataFrame criado.\n",
      "DataFrame \"pnad_trimestral_trimestre_022014.parquet\" salvo como arquivo Parquet em: db\\pnad_trimestral_trimestre_022014.parquet\n"
     ]
    }
   ],
   "source": [
    "import pnadium\n",
    "import os\n",
    "#editaveis\n",
    "ano_inicial = 2012\n",
    "ano_final = 2024\n",
    "trimestre = 2\n",
    "diretorio_db = 'db'\n",
    "arquivo_final = 'pnad_2012_2024'\n",
    "os.makedirs(diretorio_db, exist_ok=True)\n",
    "#preparando variável anos\n",
    "anos = range(ano_inicial,ano_final+1)\n",
    "# Baixa os dados do PNAD Contínua Trimestral de 2020, 2º trimestre \n",
    "for ano in anos:\n",
    "    pnadium.trimestral.download(ano=ano, t=trimestre, caminho=diretorio_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Lista de arquivos Parquet\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\_libs\\tslibs\\__init__.py:40\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalize_pydatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_supported_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m ]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes  \u001b[38;5;66;03m# pylint: disable=import-self\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m localize_pydatetime\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     Resolution,\n\u001b[0;32m     43\u001b[0m     periods_per_day,\n\u001b[0;32m     44\u001b[0m     periods_per_second,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnattype\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     NaT,\n\u001b[0;32m     48\u001b[0m     NaTType,\n\u001b[0;32m     49\u001b[0m     iNaT,\n\u001b[0;32m     50\u001b[0m     nat_strings,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32mconversion.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32moffsets.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.offsets\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:469\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[1;34m(name)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:426\u001b[0m, in \u001b[0;36m_get_module_lock\u001b[1;34m(name)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Lista de arquivos Parquet\n",
    "arquivos_parquet = sorted([os.path.join(diretorio_db, f) for f in os.listdir(diretorio_db) if f.endswith(\".parquet\")])\n",
    "# Lista das colunas que serão mantidas\n",
    "colunas_selecionadas = [\n",
    "    \"Ano\", \"UPA\", \"V1008\", \"V1014\", \"V2003\", \"UF\", \"V1022\", \"V2007\",\n",
    "    \"V20081\", \"V20082\", \"V2009\", \"V2010\", \"V3001\", \"V3002\",\n",
    "    \"V3003\", \"V3003A\", \"V3008\", \"V3009\", \"V3009A\", \"V3014\", \"V3010\",\n",
    "    \"VD3004\", \"VD3005\", \"V403312\", \"V4039\", \"V4010\", \"V4012\", \"V4014\",\n",
    "    \"V1028\"\n",
    "]\n",
    "\n",
    "# Lê apenas as colunas selecionadas\n",
    "df = pd.read_parquet(arquivos_parquet, columns=colunas_selecionadas, engine=\"pyarrow\")\n",
    "# Computa e salva o arquivo\n",
    "df.to_parquet(os.path.join(diretorio_db, \"pnad_2012_2024.parquet\"), engine=\"pyarrow\", index=False)\n",
    "print(\"✅ Banco salvo com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMEÇA AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ano', 'UPA', 'V1008', 'V1014', 'V2003', 'UF', 'V1022', 'V2007',\n",
       "       'V20081', 'V20082', 'V2009', 'V2010', 'V3001', 'V3002', 'V3003',\n",
       "       'V3003A', 'V3008', 'V3009', 'V3009A', 'V3014', 'V3010', 'VD3004',\n",
       "       'VD3005', 'V403312', 'V4039', 'V4010', 'V4012', 'V4014', 'V1028'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um banco de dados com os dados da PNAD Contínua Trimestral de 2012 a 2024\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('db/pnad_2012_2024.parquet', engine='pyarrow')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ano', 'UPA', 'V1008', 'V1014', 'V2003', 'UF', 'V1022', 'V2007',\n",
       "       'V20081', 'V20082', 'V2009', 'V2010', 'V3001', 'V3002', 'V3003',\n",
       "       'V3003A', 'V3008', 'V3009', 'V3009A', 'V3014', 'V3010', 'VD3004',\n",
       "       'VD3005', 'V403312', 'V4039', 'V4010', 'V4012', 'V4014', 'V1028'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2014 = pd.read_parquet('db/pnad_trimestral_trimestre_022014.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6694962 entries, 0 to 6694961\n",
      "Data columns (total 29 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   Ano      int64  \n",
      " 1   UPA      object \n",
      " 2   V1008    object \n",
      " 3   V1014    object \n",
      " 4   V2003    object \n",
      " 5   UF       int64  \n",
      " 6   V1022    int64  \n",
      " 7   V2007    int64  \n",
      " 8   V20081   int64  \n",
      " 9   V20082   int64  \n",
      " 10  V2009    int64  \n",
      " 11  V2010    int64  \n",
      " 12  V3001    float64\n",
      " 13  V3002    float64\n",
      " 14  V3003    float64\n",
      " 15  V3003A   float64\n",
      " 16  V3008    float64\n",
      " 17  V3009    float64\n",
      " 18  V3009A   float64\n",
      " 19  V3014    float64\n",
      " 20  V3010    float64\n",
      " 21  VD3004   float64\n",
      " 22  VD3005   float64\n",
      " 23  V403312  float64\n",
      " 24  V4039    float64\n",
      " 25  V4010    float64\n",
      " 26  V4012    float64\n",
      " 27  V4014    float64\n",
      " 28  V1028    float64\n",
      "dtypes: float64(17), int64(8), object(4)\n",
      "memory usage: 1.4+ GB\n",
      "Informações sobre o DataFrame:\n",
      "None\n",
      "Valores nulos:\n",
      "Ano              0\n",
      "UPA              0\n",
      "V1008            0\n",
      "V1014            0\n",
      "V2003            0\n",
      "UF               0\n",
      "V1022            0\n",
      "V2007            0\n",
      "V20081           0\n",
      "V20082           0\n",
      "V2009            0\n",
      "V2010            0\n",
      "V3001       423817\n",
      "V3002       423817\n",
      "V3003      6074724\n",
      "V3003A     5619833\n",
      "V3008      2119184\n",
      "V3009      5309491\n",
      "V3009A     3818798\n",
      "V3014      2592691\n",
      "V3010      5383670\n",
      "VD3004      423817\n",
      "VD3005      423817\n",
      "V403312    3976844\n",
      "V4039      3846604\n",
      "V4010      3846604\n",
      "V4012      3846604\n",
      "V4014      6315046\n",
      "V1028            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Informações sobre o DataFrame\n",
    "print(f'Informações sobre o DataFrame:\\n{df.info()}')\n",
    "# Contar os valores nulos em cada coluna\n",
    "print(f\"Valores nulos:\\n{df.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando as colunas em suas respectivas categorias conforme o dicionário de dados\n",
    "# O Pandas não aceitou os valores nulos dos inteiros então eles vieram como float64\n",
    "# Vamos transformar as colunas em Int64 para aceitar os valores nulos e para não serem lidos como float64\n",
    "colunas_para_int = ['V3001', 'V3002', 'V3003', 'V3003A', 'V3008', \n",
    "                    'V3009', 'V3009A', 'V3014', 'V3010', 'VD3004', 'VD3005', 'V4012', 'V4014']\n",
    "\n",
    "df[colunas_para_int] = df[colunas_para_int].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ano          int64\n",
       "UPA         object\n",
       "V1008       object\n",
       "V1014       object\n",
       "V2003       object\n",
       "UF           int64\n",
       "V1022        int64\n",
       "V2007        int64\n",
       "V20081       int64\n",
       "V20082       int64\n",
       "V2009        int64\n",
       "V2010        int64\n",
       "V3001        int64\n",
       "V3002        int64\n",
       "V3003        int64\n",
       "V3003A       int64\n",
       "V3008        int64\n",
       "V3009        int64\n",
       "V3009A       int64\n",
       "V3014        int64\n",
       "V3010        int64\n",
       "VD3004       int64\n",
       "VD3005       int64\n",
       "V403312    float64\n",
       "V4039      float64\n",
       "V4010      float64\n",
       "V4012        int64\n",
       "V4014        int64\n",
       "V1028      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifiquei que a variavel V20081 tem nulos como 99 e a V20082 tem nulos como 9999 \n",
    "# então vou substituir esses valores por nulos\n",
    "df['V20081'] = df['V20081'].replace(99, pd.NA)\n",
    "df['V20082'] = df['V20082'].replace(9999, pd.NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\1135826093.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"idade_cne\"].fillna(df[\"V2009\"], inplace=True)\n",
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\1135826093.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"idade_cne\"].fillna(df[\"V2009\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Calcular 'idade_cne' conforme o dicionário \n",
    "df[\"idade_cne\"] = (df[\"Ano\"] - df[\"V20082\"]).where(df[\"V20081\"] <= 3)\n",
    "df.loc[(df[\"V20081\"] > 3) & (df[\"V20082\"] != df[\"Ano\"]), \"idade_cne\"] = df[\"Ano\"] - df[\"V20082\"] - 1\n",
    "# Substituir valores NaN com a idade de referência\n",
    "df[\"idade_cne\"].fillna(df[\"V2009\"], inplace=True)\n",
    "#definindo o tipo da coluna\n",
    "df[\"idade_cne\"] = df[\"idade_cne\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6214976.0\n",
       "mean     34.622048\n",
       "std      21.586902\n",
       "min            0.0\n",
       "25%           16.0\n",
       "50%           33.0\n",
       "75%           51.0\n",
       "max          130.0\n",
       "Name: idade_cne, dtype: Float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batendo as estatísticas descritivas da idade_cne \n",
    "df['idade_cne'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos:\n",
      "Ano                  0\n",
      "UPA                  0\n",
      "V1008                0\n",
      "V1014                0\n",
      "V2003                0\n",
      "UF                   0\n",
      "V1022                0\n",
      "V2007                0\n",
      "V20081          560525\n",
      "V20082          560525\n",
      "V2009                0\n",
      "V2010                0\n",
      "V3001           423817\n",
      "V3002           423817\n",
      "V3003          6074724\n",
      "V3003A         5619833\n",
      "V3008          2119184\n",
      "V3009          5309491\n",
      "V3009A         3818798\n",
      "V3014          2592691\n",
      "V3010          5383670\n",
      "VD3004          423817\n",
      "VD3005          423817\n",
      "V403312        3976844\n",
      "V4039          3846604\n",
      "V4010          3846604\n",
      "V4012          3846604\n",
      "V4014          6315046\n",
      "V1028                0\n",
      "CO_UF                0\n",
      "CO_REGIAO            0\n",
      "CO_SEXO              0\n",
      "CO_COR_RACA          0\n",
      "idade_cne            0\n",
      "dtype: int64\n",
      "Valores únicos:\n",
      "Ano                 13\n",
      "UPA              38078\n",
      "V1008               14\n",
      "V1014               12\n",
      "V2003               25\n",
      "UF                  27\n",
      "V1022                2\n",
      "V2007                2\n",
      "V20081              12\n",
      "V20082             126\n",
      "V2009              122\n",
      "V2010                6\n",
      "V3001                2\n",
      "V3002                2\n",
      "V3003                9\n",
      "V3003A              10\n",
      "V3008                2\n",
      "V3009               12\n",
      "V3009A              14\n",
      "V3014                2\n",
      "V3010                2\n",
      "VD3004               7\n",
      "VD3005              17\n",
      "V403312           6173\n",
      "V4039              119\n",
      "V4010              434\n",
      "V4012                7\n",
      "V4014                3\n",
      "V1028          2212813\n",
      "CO_UF               27\n",
      "CO_REGIAO            5\n",
      "CO_SEXO              2\n",
      "CO_COR_RACA          6\n",
      "idade_cne          120\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6694962 entries, 0 to 6694961\n",
      "Data columns (total 34 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   Ano          Int64  \n",
      " 1   UPA          object \n",
      " 2   V1008        object \n",
      " 3   V1014        object \n",
      " 4   V2003        object \n",
      " 5   UF           Int64  \n",
      " 6   V1022        Int64  \n",
      " 7   V2007        Int64  \n",
      " 8   V20081       Int64  \n",
      " 9   V20082       Int64  \n",
      " 10  V2009        Int64  \n",
      " 11  V2010        Int64  \n",
      " 12  V3001        Int64  \n",
      " 13  V3002        Int64  \n",
      " 14  V3003        Int64  \n",
      " 15  V3003A       Int64  \n",
      " 16  V3008        Int64  \n",
      " 17  V3009        Int64  \n",
      " 18  V3009A       Int64  \n",
      " 19  V3014        Int64  \n",
      " 20  V3010        Int64  \n",
      " 21  VD3004       Int64  \n",
      " 22  VD3005       Int64  \n",
      " 23  V403312      float64\n",
      " 24  V4039        float64\n",
      " 25  V4010        float64\n",
      " 26  V4012        Int64  \n",
      " 27  V4014        Int64  \n",
      " 28  V1028        float64\n",
      " 29  CO_UF        Int64  \n",
      " 30  CO_REGIAO    Int64  \n",
      " 31  CO_SEXO      Int64  \n",
      " 32  CO_COR_RACA  Int64  \n",
      " 33  idade_cne    Int64  \n",
      "dtypes: Int64(26), float64(4), object(4)\n",
      "memory usage: 1.9+ GB\n",
      "Informações:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Verificações\n",
    "print(f\"Valores nulos:\\n{df.isnull().sum()}\")\n",
    "print(f\"Valores únicos:\\n{df.nunique()}\")\n",
    "print(f\"Informações:\\n{df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ano\n",
      "2012    96.725565\n",
      "2013    96.909282\n",
      "2014    97.180930\n",
      "2015    97.371401\n",
      "2016    97.338256\n",
      "2017    97.684898\n",
      "2018    97.975857\n",
      "2019    97.786621\n",
      "2020    97.960145\n",
      "2021    95.939731\n",
      "2022    96.284238\n",
      "2023    95.666634\n",
      "2024    95.756001\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#--------------------- METAS LIS -----------------------------\n",
    "mask_meta_2a = (\n",
    "    ((df['V3003A'] >= 4) | (df['V3003'] >=3 )) | # Estuda e cursa EF ou nível acima do EF\n",
    "    ((df['V3014'] == 1) & ((df['V3009A'] >=6 ) | (df['V3009'] >=4 ))) | # Concluiu EF e nao estuda\n",
    "    ((df['V3009A'] >=9 ) | (df['V3009'] >=7)) # Nao Concluiu, nao estuda e ultimo curso  > EF\n",
    ")\n",
    "# Criando variáveis para a meta 2A\n",
    "df['denominador_meta_2a'] = df['V1028'].where(df['idade_cne'].between(6, 14))\n",
    "df['numerador_meta_2a'] = df['denominador_meta_2a'].where(mask_meta_2a)\n",
    "\n",
    "taxa_meta_2a_PNE = (df.groupby('Ano')['numerador_meta_2a'].sum() /\n",
    "                df.groupby('Ano')['denominador_meta_2a'].sum()) * 100\n",
    "print(taxa_meta_2a_PNE)\n",
    "# 2B - PNE\n",
    "#: Percentual de pessoas de 16 anos com pelo menos o ensino fundamental completo\n",
    "# Criar a máscara para identificar quem concluiu o ensino fundamental\n",
    "mask_meta_2b = (\n",
    "    (((df[\"V3003A\"]>=6) | (df[\"V3003\"]>=5))) | # Estuda e cursa nivel > EF\n",
    "    ((df[\"V3014\"] == 1) & (((df[\"V3009A\"]>=6) | (df[\"V3009\"]>=4))))| # Não estuda mas concluiu nivel > EF\n",
    "    ((df[\"V3009A\"]>=9) | (df[\"V3009\"]>= 7))\n",
    "    )\n",
    "# Criar o denominador e o numerador para a meta 2B\n",
    "df[\"denominador_meta_2b\"] = df[\"V1028\"].where(df[\"idade_cne\"] == 16)\n",
    "df[\"numerador_meta_2b\"] = df[\"denominador_meta_2b\"].where(mask_meta_2b)\n",
    "taxa_meta_2b_PNE = (df.groupby('Ano')['numerador_meta_2b'].sum() /\n",
    "                df.groupby('Ano')['denominador_meta_2b'].sum()) * 100\n",
    "print(taxa_meta_2b_PNE)\n",
    "# 3 - PNE\n",
    "#O Indicador 3A expressa o percentual de jovens de 15 a 17 anos de idade que frequenta a escola ou que já concluiu a educação básica. \n",
    "#O Indicador 3B expressa o percentual de jovens de 15 a 17 anos de idade que frequenta o ensino médio ou que já concluiu a educação básica. \n",
    "mask_meta_3a = ((df['VD3004']>=5) | (df[\"V3002\"] == 1) )\n",
    "mask_meta_3b = (((df['V3003'].isin([5,6])) | (df[\"V3003A\"].isin([6,7]))) | (df['VD3004']>=5))\n",
    "df[\"denominador_meta_3\"] = df[\"V1028\"].where(df[\"idade_cne\"].between(15,17))\n",
    "df[\"numerador_meta_3a\"] = df[\"denominador_meta_3\"].where(mask_meta_3a)\n",
    "df[\"numerador_meta_3b\"] = df[\"denominador_meta_3\"].where(mask_meta_3b)\n",
    "metas = [\"a\",\"b\"]\n",
    "for i in metas:\n",
    "    taxa_meta_3_PNE = (df.groupby('Ano')[f'numerador_meta_3{i}'].sum() /\n",
    "                    df.groupby('Ano')[f'denominador_meta_3'].sum()) * 100\n",
    "    print(f'Meta 3 {i}:\\n{taxa_meta_3_PNE}')\n",
    "# 8 - PNE\n",
    "#8A ESCOLARIDADE MÉDIA, EM ANOS DE ESTUDO COMPLETOS, DA POPULAÇÃO DE 18 A 29 ANOS DE IDADE\n",
    "#8B ESCOLARIDADE MÉDIA, EM ANOS DE ESTUDO COMPLETOS, DA POPULAÇÃO DE 18 A 29 ANOS RESIDENTE NA ÁREA RURAL\n",
    "#8C ESCOLARIDADE MÉDIA, EM ANOS DE ESTUDO COMPLETOS, DA POPULAÇÃO DE 18 A 29 ANOS PERTENCENTE AOS 25% MAIS POBRES (RENDA DOMICILIAR PER CAPITA)\n",
    "#8D RAZÃO PERCENTUAL ENTRE A ESCOLARIDADE MÉDIA DE NEGROS E NÃO NEGROS NA FAIXA ETÁRIA DE 18 A 29 ANOS\n",
    "\n",
    "metas = [\"a\",\"b\"]\n",
    "df['denominador_meta_8a']= df['V1028'].where(df['idade_cne'].between(18, 29))\n",
    "df['numerador_meta_8a'] = df['denominador_meta_8a']*df[\"VD3005\"]\n",
    "df['denominador_meta_8b']= df['V1028'].where((df['idade_cne'].between(18, 29) & (df['V1022'] == 2)))\n",
    "df['numerador_meta_8b'] = df['denominador_meta_8b']*df[\"VD3005\"]\n",
    "#df['denominador_meta_8d']= (df['V1028'].where(df['idade_cne'].between(18, 29) & df['V1022'].isin([1,3]))*df[\"VD3005\"]).fillna(0) / (df['V1028'].where((df['idade_cne'].between(18, 29) & df['V1022'].isin([1,3]))))\n",
    "#df['numerador_meta_8d']= (df['V1028'].where(df['idade_cne'].between(18, 29) & df['V1022'].isin([2,4]))*df[\"VD3005\"]).fillna(0) / (df['V1028'].where((df['idade_cne'].between(18, 29) & df['V1022'].isin([2,4]))))\n",
    "for i in metas: \n",
    "    taxa_meta_8_PNE = (df.groupby('Ano')[f'numerador_meta_8{i}'].sum() /\n",
    "                df.groupby('Ano')[f'denominador_meta_8{i}'].sum()) \n",
    "    print(f'Meta 8 {i}:\\n{taxa_meta_8_PNE}')\n",
    "    #8D - PNE\n",
    "# Máscaras para a faixa etária e grupos de cor\n",
    "mask_branco = (df['V2009'].between(18, 29)) & (df['V2010'].isin([1, 3]))\n",
    "mask_negro  = (df['V2009'].between(18, 29)) & (df['V2010'].isin([2, 4]))\n",
    "df['numerador_meta_8d_negro']=(df['VD3005'] * df['V1028']).where(mask_negro)\n",
    "df['denominador_meta_8d_negro']=df['V1028'].where(mask_negro)\n",
    "\n",
    "df['numerador_meta_8d_branco']=(df['VD3005'] * df['V1028']).where(mask_branco)\n",
    "df['denominador_meta_8d_branco']=df['V1028'].where(mask_branco)\n",
    "# Agrupa por 'Ano' somando as contribuições de cada grupo\n",
    "soma_num_negro  = df.groupby('Ano')['numerador_meta_8d_negro'].sum()\n",
    "soma_peso_negro = df.groupby('Ano')['denominador_meta_8d_negro'].sum()\n",
    "media_negro = (soma_num_negro / soma_peso_negro).round(1)\n",
    "soma_num_branco  = df.groupby('Ano')['numerador_meta_8d_branco'].sum()\n",
    "soma_peso_branco = df.groupby('Ano')['denominador_meta_8d_branco'].sum()\n",
    "media_branco = (soma_num_branco / soma_peso_branco).round(1)\n",
    "# Calcula o Indicador 8D: (média de negros / média de não negros) * 100\n",
    "indicador = (media_negro / media_branco * 100).round(1)\n",
    "print(indicador)\n",
    "#9 - PNE\n",
    "#INDICADOR 9A: TAXA DE ALFABETIZAÇÃO DA POPULAÇÃO DE 15 ANOS OU MAIS DE IDADE\n",
    "#INDICADOR 9B: TAXA DE ANALFABETISMO FUNCIONAL DA POPULAÇÃO DE 15 ANOS OU MAIS DE IDADE\n",
    "df['denominador_meta_9'] = df['V1028'].where(df['V2009']>=15)\n",
    "df['numerador_meta_9a'] = df['denominador_meta_9'].where(df['V3001']==1)\n",
    "df['numerador_meta_9b'] = df['denominador_meta_9'].where((df['V3001']==2) | (df['VD3005']<5))\n",
    "taxa_meta_9a = (df.groupby('Ano')['numerador_meta_9a'].sum() / df.groupby('Ano')['denominador_meta_9'].sum()) * 100\n",
    "taxa_meta_9b = (df.groupby('Ano')['numerador_meta_9b'].sum() / df.groupby('Ano')['denominador_meta_9'].sum()) * 100\n",
    "print(taxa_meta_9a,taxa_meta_9b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 2A por ano: Ano\n",
      "2012    0.967256\n",
      "2013    0.969093\n",
      "2014    0.971809\n",
      "2015    0.973714\n",
      "2016    0.973383\n",
      "2017    0.976849\n",
      "2018    0.979759\n",
      "2019    0.977866\n",
      "2020    0.979601\n",
      "2021    0.959397\n",
      "2022    0.962842\n",
      "2023    0.956666\n",
      "2024    0.957560\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\4198072431.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_2a.groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "# 2A - PNE\n",
    "df['indicador_2a'] = (\n",
    "        ((df['V3003A'] >= 4) | (df['V3003'] >= 3)) |  # Estuda e cursa EF ou nível acima do EF\n",
    "        ((df['V3014'] == 1) & ((df['V3009A'] >= 6) | (df['V3009'] >= 4))) |  # Concluiu EF e não estuda\n",
    "        ((df['V3009A'] >= 9) | (df['V3009'] >= 7))  # Não Concluiu, não estuda e último curso > EF\n",
    ").astype(int) \n",
    "# Filtra os dados com idade_cne entre 6 e 14 anos\n",
    "mask_2a =df[(df['idade_cne'].between(6,14))]\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada:\n",
    "media_ano = mask_2a.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_2a'] * g['V1028']).sum() / g['V1028'].sum()\n",
    ")\n",
    "\n",
    "print(f'Média ponderada do indicador 2A por ano: {media_ano}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 2A por ano: Ano\n",
      "2012    0.682307\n",
      "2013    0.712243\n",
      "2014    0.731369\n",
      "2015    0.744455\n",
      "2016    0.746125\n",
      "2017    0.755690\n",
      "2018    0.755031\n",
      "2019    0.781666\n",
      "2020    0.818878\n",
      "2021    0.810925\n",
      "2022    0.828702\n",
      "2023    0.843244\n",
      "2024    0.859295\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2211353000.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_2b.groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "# 2B - PNE\n",
    "df['indicador_2b']  = (\n",
    "    (((df[\"V3003A\"]>=6) | (df[\"V3003\"]>=5))) | # Estuda e cursa nivel > EF\n",
    "    ((df[\"V3014\"] == 1) & (((df[\"V3009A\"]>=6) | (df[\"V3009\"]>=4))))| # Não estuda mas concluiu nivel > EF\n",
    "    ((df[\"V3009A\"]>=9) | (df[\"V3009\"]>= 7))\n",
    "    ).astype(int) \n",
    "# Filtra os dados com idade_cne == 16\n",
    "mask_2b = df[(df['idade_cne']==16)]\n",
    "\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "media_ano = mask_2b.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_2b'] * g['V1028']).sum() / g['V1028'].sum()\n",
    ")\n",
    "print(f'Média ponderada do indicador 2A por ano: {media_ano}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\907245530.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_3.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 3a por ano: Ano\n",
      "2012    0.887873\n",
      "2013    0.886735\n",
      "2014    0.892246\n",
      "2015    0.898031\n",
      "2016    0.908407\n",
      "2017    0.909810\n",
      "2018    0.915716\n",
      "2019    0.925987\n",
      "2020    0.943491\n",
      "2021    0.953101\n",
      "2022    0.943528\n",
      "2023    0.939655\n",
      "2024    0.946922\n",
      "dtype: float64\n",
      "Média ponderada do indicador 3b por ano: Ano\n",
      "2012    0.634849\n",
      "2013    0.647631\n",
      "2014    0.667192\n",
      "2015    0.675236\n",
      "2016    0.693554\n",
      "2017    0.695983\n",
      "2018    0.704843\n",
      "2019    0.726935\n",
      "2020    0.765902\n",
      "2021    0.744817\n",
      "2022    0.766967\n",
      "2023    0.769053\n",
      "2024    0.788150\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\907245530.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_3.groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "# 3 - PNE\n",
    "df['indicador_3a'] = ((df['VD3004']>=5) | (df[\"V3002\"] == 1)).astype(int)\n",
    "df['indicador_3b'] = (((df['V3003'].isin([5,6])) | (df[\"V3003A\"].isin([6,7]))) | (df['VD3004']>=5)).astype(int)\n",
    "mask_3 = df[(df['idade_cne'].between(15,17))]\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "\n",
    "for meta in ['a','b']:\n",
    "    media_ano = mask_3.groupby('Ano').apply(\n",
    "    lambda g: (g[f'indicador_3{meta}'] * g['V1028']).sum() / g['V1028'].sum())\n",
    "    print(f'Média ponderada do indicador 3{meta} por ano: {media_ano}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2507302282.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_8a.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 8A por ano: Ano\n",
      "2012    10.702229\n",
      "2013    10.823464\n",
      "2014    10.934214\n",
      "2015    11.052230\n",
      "2016    11.144339\n",
      "2017    11.282416\n",
      "2018    11.400767\n",
      "2019    11.539679\n",
      "2020    11.717825\n",
      "2021    11.761567\n",
      "2022    11.731610\n",
      "2023    11.832372\n",
      "2024    11.887172\n",
      "dtype: float64\n",
      "Média ponderada do indicador 8B por ano: Ano\n",
      "2012     8.550789\n",
      "2013     8.774575\n",
      "2014     8.971661\n",
      "2015     9.221664\n",
      "2016     9.380817\n",
      "2017     9.593481\n",
      "2018     9.707433\n",
      "2019     9.932897\n",
      "2020    10.242937\n",
      "2021    10.427308\n",
      "2022    10.322139\n",
      "2023    10.392062\n",
      "2024    10.468462\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2507302282.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_8b.groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "# 8 - PNE\n",
    "df['indicador_8'] = df[\"VD3005\"]\n",
    "mask_8a = df[(df['idade_cne'].between(18, 29))]\n",
    "mask_8b = df[((df['idade_cne'].between(18, 29)) & (df['V1022'] == 2))] \n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "\n",
    "media_ano = mask_8a.groupby('Ano').apply(\n",
    "lambda g: (g['indicador_8'] * g['V1028']).sum() / g['V1028'].sum())\n",
    "print(f'Média ponderada do indicador 8A por ano: {media_ano}')\n",
    "media_ano = mask_8b.groupby('Ano').apply(\n",
    "lambda g: (g['indicador_8'] * g['V1028']).sum() / g['V1028'].sum())\n",
    "print(f'Média ponderada do indicador 8B por ano: {media_ano}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2318230618.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_negro = mask_8.groupby('Ano').apply(lambda g:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ano\n",
      "2012    86.253246\n",
      "2013    86.843496\n",
      "2014    87.222380\n",
      "2015    88.118946\n",
      "2016    88.275546\n",
      "2017    89.314143\n",
      "2018    89.660044\n",
      "2019    89.786243\n",
      "2020    90.468702\n",
      "2021    91.217500\n",
      "2022    91.392034\n",
      "2023    91.649398\n",
      "2024    91.529703\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2318230618.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_branco = mask_8.groupby('Ano').apply(lambda g:\n"
     ]
    }
   ],
   "source": [
    "# 8D - PNE\n",
    "df['branco'] = df['V2010'].isin([1, 3]).astype(int)\n",
    "df['negro'] = df['V2010'].isin([2, 4]).astype(int)\n",
    "mask_8 = df[(df['V2009'].between(18,29))]\n",
    "\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano\n",
    "media_negro = mask_8.groupby('Ano').apply(lambda g: \n",
    "    (g['negro'] * g['indicador_8'] * g['V1028']).sum() / (g['V1028'] * g['negro']).sum()\n",
    ")\n",
    "\n",
    "media_branco = mask_8.groupby('Ano').apply(lambda g: \n",
    "    (g['branco'] * g['indicador_8'] * g['V1028']).sum() / (g['V1028'] * g['branco']).sum()\n",
    ")\n",
    "media_ano = (media_negro / media_branco) * 100\n",
    "\n",
    "print(media_ano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\4170819566.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_9.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 9a por ano: Ano\n",
      "2012    91.848909\n",
      "2013    92.263238\n",
      "2014    92.584138\n",
      "2015    92.856372\n",
      "2016    93.297511\n",
      "2017    93.499475\n",
      "2018    93.713380\n",
      "2019    93.909498\n",
      "2020    94.781134\n",
      "2021    95.030108\n",
      "2022    94.379482\n",
      "2023    94.565616\n",
      "2024    94.726896\n",
      "dtype: float64\n",
      "Média ponderada do indicador 9b por ano: Ano\n",
      "2012    17.688807\n",
      "2013    16.752067\n",
      "2014    15.920504\n",
      "2015    15.169624\n",
      "2016    15.614310\n",
      "2017    14.258181\n",
      "2018    13.577017\n",
      "2019    13.107649\n",
      "2020    11.523175\n",
      "2021    11.413727\n",
      "2022    12.318151\n",
      "2023    12.279606\n",
      "2024    11.929919\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\4170819566.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_9.groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "#9 - PNE\n",
    "\n",
    "df['indicador_9a'] = (df['V3001']==1).astype(int)\n",
    "df['indicador_9b'] = ((df['V3001']==2) | (df['VD3005']<5)).astype(int)\n",
    "mask_9 = df[(df['V2009']>=15)]\n",
    "\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "for meta in ['a','b']:\n",
    "    media_ano = mask_9.groupby('Ano').apply(\n",
    "    lambda g: (g[f'indicador_9{meta}'] * g['V1028']).sum() / g['V1028'].sum()) * 100\n",
    "    print(f'Média ponderada do indicador 9{meta} por ano: {media_ano}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2700005297.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = df.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 12A por ano:\n",
      "Ano\n",
      "2012    0.299664\n",
      "2013    0.305495\n",
      "2014    0.318261\n",
      "2015    0.335464\n",
      "2016    0.345831\n",
      "2017    0.335831\n",
      "2018    0.362732\n",
      "2019    0.362139\n",
      "2020    0.387063\n",
      "2021    0.374186\n",
      "2022    0.385266\n",
      "2023    0.405489\n",
      "2024    0.428693\n",
      "dtype: float64\n",
      "Média ponderada do indicador 12b por ano: Ano\n",
      "2012    0.195329\n",
      "2013    0.199196\n",
      "2014    0.212354\n",
      "2015    0.218847\n",
      "2016    0.230627\n",
      "2017    0.224468\n",
      "2018    0.242886\n",
      "2019    0.247128\n",
      "2020    0.265745\n",
      "2021    0.255468\n",
      "2022    0.249613\n",
      "2023    0.258910\n",
      "2024    0.270599\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_13012\\2700005297.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano2 = df[mask_12].groupby('Ano').apply(\n"
     ]
    }
   ],
   "source": [
    "#12 - PNE\n",
    "df['indicador_12b'] = (((df['V3003A'] >= 8) | (df['V3003'] >=7 )) | # Estuda e cursa facul ou nível acima da facul\n",
    "    ((df['V3014'] == 1) & ((df['V3009A'] >=12 ) | (df['V3009'] >=10 ))) | # Concluiu EF e nao estuda\n",
    "    ((df['V3009A'] > 12 ) | (df['V3009'] > 10))\n",
    ").astype(int)\n",
    "df['indicador_12a'] = ((df['V3003A'] == 8) | (df['V3003'] == 7)).astype(int)\n",
    "# Máscara para selecionar apenas pessoas de 18 a 24 anos\n",
    "mask_12 = df['V2009'].between(18, 24)\n",
    "\n",
    "\n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "media_ano = df.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_12a'] * g['V1028']).sum() / g.loc[mask_12, 'V1028'].sum())\n",
    "print(f'Média ponderada do indicador 12A por ano:\\n{media_ano}')\n",
    "media_ano2 = df[mask_12].groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_12b'] * g['V1028']).sum() / g['V1028'].sum())\n",
    "\n",
    "print(f'Média ponderada do indicador 12b por ano: {media_ano2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando região\n",
    "df['REGIAO'] = df[\"UF\"].astype(str).str[0].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>UPA</th>\n",
       "      <th>V1008</th>\n",
       "      <th>V1014</th>\n",
       "      <th>V2003</th>\n",
       "      <th>UF</th>\n",
       "      <th>urbana_rural</th>\n",
       "      <th>sexo</th>\n",
       "      <th>V20081</th>\n",
       "      <th>V20082</th>\n",
       "      <th>...</th>\n",
       "      <th>indicador_3a</th>\n",
       "      <th>indicador_3b</th>\n",
       "      <th>indicador_8</th>\n",
       "      <th>branco</th>\n",
       "      <th>negro</th>\n",
       "      <th>indicador_9a</th>\n",
       "      <th>indicador_9b</th>\n",
       "      <th>indicador_12b</th>\n",
       "      <th>indicador_12a</th>\n",
       "      <th>REGIAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1962</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1957</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1987</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>05</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1988</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1988</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>05</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1960</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>110000153</td>\n",
       "      <td>05</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano        UPA V1008 V1014 V2003  UF  urbana_rural  sexo V20081 V20082  \\\n",
       "0  2012  110000153    01     2    01  11             1     2      1   1940   \n",
       "1  2012  110000153    02     2    01  11             1     2      6   1962   \n",
       "2  2012  110000153    03     2    01  11             1     1      8   1960   \n",
       "3  2012  110000153    03     2    02  11             1     2      5   1957   \n",
       "4  2012  110000153    03     2    03  11             1     2     12   1976   \n",
       "5  2012  110000153    03     2    04  11             1     1     11   1987   \n",
       "6  2012  110000153    03     2    05  11             1     1     11   1988   \n",
       "7  2012  110000153    04     2    01  11             1     2      7   1988   \n",
       "8  2012  110000153    05     2    01  11             1     1      8   1960   \n",
       "9  2012  110000153    05     2    02  11             1     2      8   1961   \n",
       "\n",
       "   ...  indicador_3a  indicador_3b  indicador_8  branco  negro  indicador_9a  \\\n",
       "0  ...             0             0            9       1      0             1   \n",
       "1  ...             0             0            9       1      0             1   \n",
       "2  ...             0             0            9       0      1             1   \n",
       "3  ...             1             1           12       0      1             1   \n",
       "4  ...             1             1           14       1      0             1   \n",
       "5  ...             1             1           12       0      1             1   \n",
       "6  ...             1             1           12       0      1             1   \n",
       "7  ...             0             0            9       1      0             1   \n",
       "8  ...             1             1           12       0      1             1   \n",
       "9  ...             0             0            8       0      1             1   \n",
       "\n",
       "   indicador_9b  indicador_12b  indicador_12a  REGIAO  \n",
       "0             0              0              0       1  \n",
       "1             0              0              0       1  \n",
       "2             0              0              0       1  \n",
       "3             0              0              0       1  \n",
       "4             0              1              1       1  \n",
       "5             0              0              0       1  \n",
       "6             0              0              0       1  \n",
       "7             0              0              0       1  \n",
       "8             0              0              0       1  \n",
       "9             0              0              0       1  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = { \"V2007\": \"sexo\",\"V2010\": \"cor\",\"V1022\": \"urbana_rural\", \"V2009\":\"idade\",\"V1028\":\"peso\"}\n",
    "df_agg = df\n",
    "df_agg.rename(columns=labels, inplace=True)\n",
    "df_agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          idade  urbana_rural  cor  sexo   Ano  UF  REGIAO  indicador_2a  \\\n",
       "0            0             1    1     1  2012  11       1             0   \n",
       "1            0             1    1     1  2012  12       1             0   \n",
       "2            0             1    1     1  2012  13       1             0   \n",
       "3            0             1    1     1  2012  14       1             0   \n",
       "4            0             1    1     1  2012  15       1             0   \n",
       "...        ...           ...  ...   ...   ...  ..     ...           ...   \n",
       "2533780    120             1    1     2  2014  52       5             0   \n",
       "2533781    121             1    4     1  2015  17       1             1   \n",
       "2533782    122             1    4     1  2012  41       4             0   \n",
       "2533783    122             1    4     2  2012  41       4             0   \n",
       "2533784    130             1    1     2  2013  25       2             0   \n",
       "\n",
       "         indicador_2b  indicador_3a  indicador_3b  indicador_8  branco  negro  \\\n",
       "0                   0             0             0            0       1      0   \n",
       "1                   0             0             0            0       1      0   \n",
       "2                   0             0             0            0       1      0   \n",
       "3                   0             0             0            0       1      0   \n",
       "4                   0             0             0            0       1      0   \n",
       "...               ...           ...           ...          ...     ...    ...   \n",
       "2533780             0             0             0            0       1      0   \n",
       "2533781             1             1             1           12       0      1   \n",
       "2533782             0             0             0            0       0      1   \n",
       "2533783             0             0             0            0       0      1   \n",
       "2533784             0             0             0            5       1      0   \n",
       "\n",
       "         indicador_9a  indicador_9b  indicador_12b  indicador_12a  idade_cne  \\\n",
       "0                   0             1              0              0          0   \n",
       "1                   0             1              0              0          0   \n",
       "2                   0             1              0              0          0   \n",
       "3                   0             1              0              0          0   \n",
       "4                   0             1              0              0          0   \n",
       "...               ...           ...            ...            ...        ...   \n",
       "2533780             1             1              0              0        120   \n",
       "2533781             1             0              0              0        120   \n",
       "2533782             0             1              0              0        122   \n",
       "2533783             0             1              0              0        122   \n",
       "2533784             1             0              0              0        130   \n",
       "\n",
       "                 peso  \n",
       "0         4990.718104  \n",
       "1         2691.176104  \n",
       "2         6826.924694  \n",
       "3          469.154682  \n",
       "4        12684.047533  \n",
       "...               ...  \n",
       "2533780    230.265894  \n",
       "2533781    213.806348  \n",
       "2533782    458.566533  \n",
       "2533783    458.566533  \n",
       "2533784    138.930756  \n",
       "\n",
       "[2533785 rows x 20 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Banco agregado apenas com as variaveis para calcular as mestas\n",
    "break_cols = ['idade','urbana_rural','cor','sexo','Ano','UF','REGIAO','indicador_2a', 'indicador_2b', 'indicador_3a',\n",
    "'indicador_3b', 'indicador_8', 'branco', 'negro', 'indicador_9a',\n",
    "'indicador_9b', 'indicador_12b', 'indicador_12a', 'idade_cne',]\n",
    "df_agg = df.groupby(break_cols, as_index=False).agg(peso=(\"peso\", \"sum\"))\n",
    "df_agg.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Banco salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#Salvando banco agregado\n",
    "\n",
    "df_agg.to_parquet('banco_metas.parquet', index=False, engine=\"pyarrow\")\n",
    "print(\"✅ Banco salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_2a.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 2A por ano: Ano\n",
      "2012    0.967256\n",
      "2013    0.969093\n",
      "2014    0.971809\n",
      "2015    0.973714\n",
      "2016    0.973383\n",
      "2017    0.976849\n",
      "2018    0.979759\n",
      "2019    0.977866\n",
      "2020    0.979601\n",
      "2021    0.959397\n",
      "2022    0.962842\n",
      "2023    0.956666\n",
      "2024    0.957560\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_2b.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 2B por ano: Ano\n",
      "2012    0.682307\n",
      "2013    0.712243\n",
      "2014    0.731369\n",
      "2015    0.744455\n",
      "2016    0.746125\n",
      "2017    0.755690\n",
      "2018    0.755031\n",
      "2019    0.781666\n",
      "2020    0.818878\n",
      "2021    0.810925\n",
      "2022    0.828702\n",
      "2023    0.843244\n",
      "2024    0.859295\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_3.groupby('Ano').apply(\n",
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_3.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 3a por ano: Ano\n",
      "2012    0.887873\n",
      "2013    0.886735\n",
      "2014    0.892246\n",
      "2015    0.898031\n",
      "2016    0.908407\n",
      "2017    0.909810\n",
      "2018    0.915716\n",
      "2019    0.925987\n",
      "2020    0.943491\n",
      "2021    0.953101\n",
      "2022    0.943528\n",
      "2023    0.939655\n",
      "2024    0.946922\n",
      "dtype: float64\n",
      "Média ponderada do indicador 3b por ano: Ano\n",
      "2012    0.634849\n",
      "2013    0.647631\n",
      "2014    0.667192\n",
      "2015    0.675236\n",
      "2016    0.693554\n",
      "2017    0.695983\n",
      "2018    0.704843\n",
      "2019    0.726935\n",
      "2020    0.765902\n",
      "2021    0.744817\n",
      "2022    0.766967\n",
      "2023    0.769053\n",
      "2024    0.788150\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_8a.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 8A por ano: Ano\n",
      "2012    10.702229\n",
      "2013    10.823464\n",
      "2014    10.934214\n",
      "2015    11.052230\n",
      "2016    11.144339\n",
      "2017    11.282416\n",
      "2018    11.400767\n",
      "2019    11.539679\n",
      "2020    11.717825\n",
      "2021    11.761567\n",
      "2022    11.731610\n",
      "2023    11.832372\n",
      "2024    11.887172\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_8b.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 8B por ano: Ano\n",
      "2012     8.550789\n",
      "2013     8.774575\n",
      "2014     8.971661\n",
      "2015     9.221664\n",
      "2016     9.380817\n",
      "2017     9.593481\n",
      "2018     9.707433\n",
      "2019     9.932897\n",
      "2020    10.242937\n",
      "2021    10.427308\n",
      "2022    10.322139\n",
      "2023    10.392062\n",
      "2024    10.468462\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_negro = mask_8.groupby('Ano').apply(lambda g:\n",
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_branco = mask_8.groupby('Ano').apply(lambda g:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ano\n",
      "2012    86.253246\n",
      "2013    86.843496\n",
      "2014    87.222380\n",
      "2015    88.118946\n",
      "2016    88.275546\n",
      "2017    89.314143\n",
      "2018    89.660044\n",
      "2019    89.786243\n",
      "2020    90.468702\n",
      "2021    91.217500\n",
      "2022    91.392034\n",
      "2023    91.649398\n",
      "2024    91.529703\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_9.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 9a por ano: Ano\n",
      "2012    91.848909\n",
      "2013    92.263238\n",
      "2014    92.584138\n",
      "2015    92.856372\n",
      "2016    93.297511\n",
      "2017    93.499475\n",
      "2018    93.713380\n",
      "2019    93.909498\n",
      "2020    94.781134\n",
      "2021    95.030108\n",
      "2022    94.379482\n",
      "2023    94.565616\n",
      "2024    94.726896\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = mask_9.groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 9b por ano: Ano\n",
      "2012    17.688807\n",
      "2013    16.752067\n",
      "2014    15.920504\n",
      "2015    15.169624\n",
      "2016    15.614310\n",
      "2017    14.258181\n",
      "2018    13.577017\n",
      "2019    13.107649\n",
      "2020    11.523175\n",
      "2021    11.413727\n",
      "2022    12.318151\n",
      "2023    12.279606\n",
      "2024    11.929919\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano = df_agg.groupby('Ano').apply(\n",
      "C:\\Users\\lisca\\AppData\\Local\\Temp\\ipykernel_16168\\365813958.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  media_ano2 = df_agg[mask_12].groupby('Ano').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ponderada do indicador 12A por ano:\n",
      "Ano\n",
      "2012    0.299664\n",
      "2013    0.305495\n",
      "2014    0.318261\n",
      "2015    0.335464\n",
      "2016    0.345831\n",
      "2017    0.335831\n",
      "2018    0.362732\n",
      "2019    0.362139\n",
      "2020    0.387063\n",
      "2021    0.374186\n",
      "2022    0.385266\n",
      "2023    0.405489\n",
      "2024    0.428693\n",
      "dtype: float64\n",
      "Média ponderada do indicador 12b por ano: Ano\n",
      "2012    0.195329\n",
      "2013    0.199196\n",
      "2014    0.212354\n",
      "2015    0.218847\n",
      "2016    0.230627\n",
      "2017    0.224468\n",
      "2018    0.242886\n",
      "2019    0.247128\n",
      "2020    0.265745\n",
      "2021    0.255468\n",
      "2022    0.249613\n",
      "2023    0.258910\n",
      "2024    0.270599\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Teste banco agregado\n",
    "mask_2a =df_agg[(df_agg['idade_cne'].between(6,14))]\n",
    "media_ano = mask_2a.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_2a'] * g['peso']).sum() / g['peso'].sum()\n",
    ")\n",
    "\n",
    "print(f'Média ponderada do indicador 2A por ano: {media_ano}')\n",
    "mask_2b = df[(df['idade_cne']==16)]\n",
    "\n",
    "media_ano = mask_2b.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_2b'] * g['peso']).sum() / g['peso'].sum()\n",
    ")\n",
    "print(f'Média ponderada do indicador 2B por ano: {media_ano}')\n",
    "\n",
    "\n",
    "mask_3 = df_agg[(df_agg['idade_cne'].between(15,17))]\n",
    "for meta in ['a','b']:\n",
    "    media_ano = mask_3.groupby('Ano').apply(\n",
    "    lambda g: (g[f'indicador_3{meta}'] * g['peso']).sum() / g['peso'].sum())\n",
    "    print(f'Média ponderada do indicador 3{meta} por ano: {media_ano}')\n",
    "\n",
    "mask_8a = df[(df['idade_cne'].between(18, 29))]\n",
    "mask_8b = df[((df['idade_cne'].between(18, 29)) & (df['urbana_rural'] == 2))] \n",
    "#-------------------------------- TESTE -----------------------------------\n",
    "# Calcula a média ponderada por ano:\n",
    "\n",
    "media_ano = mask_8a.groupby('Ano').apply(\n",
    "lambda g: (g['indicador_8'] * g['peso']).sum() / g['peso'].sum())\n",
    "print(f'Média ponderada do indicador 8A por ano: {media_ano}')\n",
    "media_ano = mask_8b.groupby('Ano').apply(\n",
    "lambda g: (g['indicador_8'] * g['peso']).sum() / g['peso'].sum())\n",
    "print(f'Média ponderada do indicador 8B por ano: {media_ano}')\n",
    "\n",
    "mask_8 = df_agg[(df_agg['idade'].between(18,29))]\n",
    "# Calcula a média ponderada por ano\n",
    "media_negro = mask_8.groupby('Ano').apply(lambda g: \n",
    "    (g['negro'] * g['indicador_8'] * g['peso']).sum() / (g['peso'] * g['negro']).sum()\n",
    ")\n",
    "\n",
    "media_branco = mask_8.groupby('Ano').apply(lambda g: \n",
    "    (g['branco'] * g['indicador_8'] * g['peso']).sum() / (g['peso'] * g['branco']).sum()\n",
    ")\n",
    "media_ano = (media_negro / media_branco) * 100\n",
    "\n",
    "print(media_ano)\n",
    "\n",
    "mask_9 = df_agg[(df_agg['idade']>=15)]\n",
    "\n",
    "for meta in ['a','b']:\n",
    "    media_ano = mask_9.groupby('Ano').apply(\n",
    "    lambda g: (g[f'indicador_9{meta}'] * g['peso']).sum() / g['peso'].sum()) * 100\n",
    "    print(f'Média ponderada do indicador 9{meta} por ano: {media_ano}')\n",
    "\n",
    "\n",
    "mask_12 = df_agg['idade'].between(18, 24)\n",
    "media_ano = df_agg.groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_12a'] * g['peso']).sum() / g.loc[mask_12, 'peso'].sum())\n",
    "print(f'Média ponderada do indicador 12A por ano:\\n{media_ano}')\n",
    "media_ano2 = df_agg[mask_12].groupby('Ano').apply(\n",
    "    lambda g: (g['indicador_12b'] * g['peso']).sum() / g['peso'].sum())\n",
    "\n",
    "print(f'Média ponderada do indicador 12b por ano: {media_ano2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('UF', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('UF', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V1022', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V2007', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V2010', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V3001', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V3002', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V3002A', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V3008', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "C:\\Users\\lisca\\AppData\\Roaming\\Python\\Python313\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('V3014', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPA</th>\n",
       "      <th>V1008</th>\n",
       "      <th>V1014</th>\n",
       "      <th>V2003</th>\n",
       "      <th>Unidade da Federação</th>\n",
       "      <th>Situação do domicílio</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Mês de nascimento</th>\n",
       "      <th>Ano de nascimento</th>\n",
       "      <th>Idade do morador na data de referência</th>\n",
       "      <th>...</th>\n",
       "      <th>Nível de instrução mais elevado alcançado</th>\n",
       "      <th>Anos de estudo (pessoas de 5 anos ou mais de idade)</th>\n",
       "      <th>Rendimento bruto/retirada mensal</th>\n",
       "      <th>Horas trabalhadas por semana</th>\n",
       "      <th>Código da ocupação</th>\n",
       "      <th>Nesse trabalho, ... era:</th>\n",
       "      <th>Esse trabalho era na área:</th>\n",
       "      <th>Peso do domicílio e das pessoas</th>\n",
       "      <th>Ano de referência</th>\n",
       "      <th>Região</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110000153</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Mulher</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>112.361428</td>\n",
       "      <td>2012</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110000153</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Mulher</td>\n",
       "      <td>6</td>\n",
       "      <td>1962</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>400.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9111.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>103.038283</td>\n",
       "      <td>2012</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Homem</td>\n",
       "      <td>8</td>\n",
       "      <td>1960</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>145.680906</td>\n",
       "      <td>2012</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Mulher</td>\n",
       "      <td>5</td>\n",
       "      <td>1957</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>800.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4411.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>145.680906</td>\n",
       "      <td>2012</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110000153</td>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Mulher</td>\n",
       "      <td>12</td>\n",
       "      <td>1976</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>622.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>145.680906</td>\n",
       "      <td>2012</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UPA V1008 V1014 V2003 Unidade da Federação Situação do domicílio  \\\n",
       "0  110000153    01     2    01             Rondônia                Urbana   \n",
       "1  110000153    02     2    01             Rondônia                Urbana   \n",
       "2  110000153    03     2    01             Rondônia                Urbana   \n",
       "3  110000153    03     2    02             Rondônia                Urbana   \n",
       "4  110000153    03     2    03             Rondônia                Urbana   \n",
       "\n",
       "     Sexo  Mês de nascimento  Ano de nascimento  \\\n",
       "0  Mulher                  1               1940   \n",
       "1  Mulher                  6               1962   \n",
       "2   Homem                  8               1960   \n",
       "3  Mulher                  5               1957   \n",
       "4  Mulher                 12               1976   \n",
       "\n",
       "   Idade do morador na data de referência  ...  \\\n",
       "0                                      72  ...   \n",
       "1                                      49  ...   \n",
       "2                                      51  ...   \n",
       "3                                      55  ...   \n",
       "4                                      35  ...   \n",
       "\n",
       "  Nível de instrução mais elevado alcançado  \\\n",
       "0                                         3   \n",
       "1                                         3   \n",
       "2                                         3   \n",
       "3                                         5   \n",
       "4                                         6   \n",
       "\n",
       "  Anos de estudo (pessoas de 5 anos ou mais de idade)  \\\n",
       "0                                                  9    \n",
       "1                                                  9    \n",
       "2                                                  9    \n",
       "3                                                 12    \n",
       "4                                                 14    \n",
       "\n",
       "  Rendimento bruto/retirada mensal Horas trabalhadas por semana  \\\n",
       "0                              NaN                          NaN   \n",
       "1                            400.0                         32.0   \n",
       "2                           1200.0                         56.0   \n",
       "3                            800.0                         30.0   \n",
       "4                            622.0                         70.0   \n",
       "\n",
       "   Código da ocupação  Nesse trabalho, ... era: Esse trabalho era na área:  \\\n",
       "0                 NaN                      <NA>                       <NA>   \n",
       "1              9111.0                         1                       <NA>   \n",
       "2              1120.0                         5                       <NA>   \n",
       "3              4411.0                         4                          2   \n",
       "4              1412.0                         6                       <NA>   \n",
       "\n",
       "   Peso do domicílio e das pessoas  Ano de referência Região  \n",
       "0                       112.361428               2012  Norte  \n",
       "1                       103.038283               2012  Norte  \n",
       "2                       145.680906               2012  Norte  \n",
       "3                       145.680906               2012  Norte  \n",
       "4                       145.680906               2012  Norte  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criar variavel regiao com base na UF\n",
    "df['Região'] = df['UF'].astype(str).str[0].astype(int).map({\n",
    " 1: 'Norte', \n",
    "    2: 'Nordeste', \n",
    "    3: 'Sudeste', \n",
    "    4: 'Sul', \n",
    "    5: 'Centro-Oeste'\n",
    "} )\n",
    "\n",
    "# Mapear os rótulos das variáveis\n",
    "variaveis_labels = {\n",
    "    \"Ano\": \"Ano de referência\",\n",
    "    \"UF\": \"Unidade da Federação\",\n",
    "    \"V1022\": \"Situação do domicílio\",\n",
    "    \"V2007\": \"Sexo\",\n",
    "    \"V20081\": \"Mês de nascimento\",\n",
    "    \"V20082\": \"Ano de nascimento\",\n",
    "    \"V2009\": \"Idade do morador na data de referência\",\n",
    "    \"V2010\": \"Cor ou raça\",\n",
    "    \"V3001\": \"... sabe ler e escrever?\",\n",
    "    \"V3002\": \"... frequenta escola?\",\n",
    "    \"V3003\": \"Qual é o curso que ... frequenta?\",\n",
    "    \"V3003A\": \"Qual é o curso que ... frequenta? (detalhado)\",\n",
    "    \"V3008\": \"Anteriormente ... frequentou escola?\",\n",
    "    \"V3009\": \"Qual foi o curso mais elevado que ... frequentou anteriormente?\",\n",
    "    \"V3009A\": \"Qual foi o curso mais elevado que ... frequentou anteriormente? (detalhado)\",\n",
    "    \"V3010\": \"A duração deste curso que ... frequentou anteriormente era de:\",\n",
    "    \"V3014\": \"... concluiu este curso que frequentou anteriormente\",\n",
    "    \"VD3004\": \"Nível de instrução mais elevado alcançado\",\n",
    "    \"VD3005\": \"Anos de estudo (pessoas de 5 anos ou mais de idade)\",\n",
    "    \"V1028\": \"Peso do domicílio e das pessoas\",\n",
    "    \"V403312\": \"Rendimento bruto/retirada mensal\",\n",
    "    \"V4039\": \"Horas trabalhadas por semana\",\n",
    "    \"V4010\": \"Código da ocupação\",\n",
    "    \"V4012\": \"Nesse trabalho, ... era:\",\n",
    "    \"V4014\": \"Esse trabalho era na área:\",\n",
    "}\n",
    "\n",
    "# Mapear os valores das variáveis\n",
    "valores_labels = {\n",
    "    \"UF\": {\n",
    "        11: \"Rondônia\", 12: \"Acre\", 13: \"Amazonas\", 14: \"Roraima\", 15: \"Pará\", 16: \"Amapá\", 17: \"Tocantins\",\n",
    "        21: \"Maranhão\", 22: \"Piauí\", 23: \"Ceará\", 24: \"Rio Grande do Norte\", 25: \"Paraíba\", 26: \"Pernambuco\",\n",
    "        27: \"Alagoas\", 28: \"Sergipe\", 29: \"Bahia\", 31: \"Minas Gerais\", 32: \"Espírito Santo\", 33: \"Rio de Janeiro\",\n",
    "        35: \"São Paulo\", 41: \"Paraná\", 42: \"Santa Catarina\", 43: \"Rio Grande do Sul\", 50: \"Mato Grosso do Sul\",\n",
    "        51: \"Mato Grosso\", 52: \"Goiás\", 53: \"Distrito Federal\"\n",
    "    },\n",
    "    \"V1022\": {1: \"Urbana\", 2: \"Rural\"},\n",
    "    \"V2007\": {1: \"Homem\", 2: \"Mulher\"},\n",
    "    \"V2010\": {1: \"Branca\", 2: \"Preta\", 3: \"Amarela\", 4: \"Parda\", 5: \"Indígena\", 9: \"Ignorado\"},\n",
    "    \"V3001\": {1: \"Sim\", 2: \"Não\"},\n",
    "    \"V3002\": {1: \"Sim\", 2: \"Não\"},\n",
    "    \"V3008\": {1: \"Sim\", 2: \"Não\"},\n",
    "    \"V3014\": {1: \"Sim\", 2: \"Não\"},\n",
    "}\n",
    "\n",
    "# Aplicar os mapeamentos\n",
    "for col, mapping in valores_labels.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping)\n",
    "df = df.rename(columns=variaveis_labels)\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
